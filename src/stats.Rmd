---
title: "Statistical summary functions"
author: "Suman Sahil, Steve Simon"
date: "Creation date: 2019-09-24"
output: powerpoint_presentation
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment="")
suppressMessages(suppressWarnings(library(knitr)))
suppressMessages(suppressWarnings(library(magrittr)))
suppressMessages(suppressWarnings(library(sqldf)))

```

```{r connect}
library(sqldf)
db <- dbConnect(SQLite(), dbname="../data/fat.sqlite")
```

### Statistical summary functions

+ SQL can produce a handful of summary statistics.
+ Common to all versions of SQL
  + count, avg, sum, min, max
+ Standard deviation function is not consistent
  + Not available in SQLite
  + stddev, stdev, stdevp, stdev_samp
  
<div class="notes">

It will not replace your favorite statistical package, but sometimes calculating a few of these statistics in SQL can greatly simplify your life.

The count, average, sum, min, and max functions are identical across all versions of SQL, but the standard deviation function is not. It is just not available at all in SQLite. Depending on which version of SQL you are using, you might use stddev with two "d"'s or stdev with only one "d" and you might have two different versions of the standard deviation in the same version of SQL. One would use n-1 in the denominator and the other would use n in the denominator.

I would recommend that you avoid the use of a standard deviation calculation in SQL, if you can.

</div>

### Min, max, and avg functions
```{r min-and-max}
sql_code <- 
 "select max(age), min(age)
  from  fat"
```
+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

The min  and max functions behave just as you'd suspect.

</div>

### Be sure to rename your variables
```{r renamed-min-and-max}
sql_code <- 
 "select 
  max(age) as oldest, 
  min(age) as youngest
  from  fat"
```
+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

The default names that SQL gives to your statistical functions include parentheses. If you know anything about The min, max, and avg functions behave just as you'd suspect.

</div>

### Computing a range

```{r range}
sql_code <- 
 "select 
  max(age)-min(age) as age_range
  from  fat"
```
+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

You can combine these functions with a subtraction operator to get a range.

</div>

### computing an average

```{r average}
sql_code <- 
 "select avg(age) as average_age
  from  fat"
```
+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

The average also behaves as you'd suspect. Notice that SQL produces five decimal places for the average age. If you are using the average in some intermediate calculations, then keeping all this precision is a good idea. But if your only reason for computing the average is for displaying it's value in a table, then you should round your results.

</div>

### Rounding the average

```{r rounded-average}
sql_code <- 
 "select round(avg(age),1) as average_age
  from  fat"
```
+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

Here is how you would round the average. Note that in most settings, I would prefer to round an average age to the nearest year. No one really cares if the average age is 44.9 versus 45. Even half a year is irrelevant unless you are talking about children. In geneal, I would encourage you to round aggressively.

</div>

### When should you use these statistical functions
+ All these functions are available in SAS and R
+ Use statistical functions in SQL if you want
  + to save time and space
  + to simplify your SAS or R code

<div class="notes">

All of these functions, of course, are available in SAS or R. An important question if why you would use SQL to calculate these statistics instead?

The biggest reason is time and space. SQL excels at managing massive amounts of data. It uses an efficent storage model and an efficient retrieval model. That's not to say that the storage and retrieval models in SAS and R are substandard. It's just that SQL has been designed from the ground up to handle massive amounts of data. It does a lot of things behind the scenes to speed things up.

There may be advantages from the hardware end as well. When you run a database query, you send a request from your client computer, which may be a humble desktop or laptop computer to a power server computer with multiple processors and massive storage systems that run in parallel.

There are exceptions, but any data management work that you can do in SQL will usually lead to savings in time.

Storage is also a consideration. All the examples that you've seen in this class involve just a few dozen or maybe a few hundred records, but in the real world, your database may contain millions or even billions of records. This amount of data would not fit on your local computer, and even if it did, you would have trouble downloading it through even a high speed Internet connection. It would be better to ask for your summary statistics that the thousands or millions of records needed to produce those summary statistics.

You might prefer to have SQL do the summarizations if it simplifies the SAS or R code. In general, SQL code is easier for a non-programmer to read than SAS or R code. So using SQL might make your code a bit easier to folow.

</div>

### When should you use these statistical functions (2/2)
+ Use statistical functions in SAS or R if you need
  + to store both the summary statistics AND the raw data
  + to account for variation
  + sophisticated summary statistics
  
<div class="notes">

In some applications, you will need SAS or R to have access both the summary statistics and the raw data. This might be for plotting purposes, for example, where you would show both the summary staistics and the individual data points. If you need to account for variation, especially variation across multiple levels of a hierarchy, then you shoud do the summarization in SAS or R. It also goes without saying that if you need a summary statistic that is even just a tiny bit more complicated than a standard deviation, then you need to use SAS or R.

</div>

### Count funtion
```{r counting}
sql_code <- 
 "select count(case_number) as n_rows
  from fat"
```
+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

The COUNT function is, in my opinion, one of the most useful summary functions. It allows you to quickly identify the number of records in your query. You can use COUNT on any field in your database and you should get the same answer, with one exception, which you will see in the section on NULL values.

The name chosen by SQL for the result of COUNT is not a legal R name,so you would normally use the AS statement to create a better name.

</div>

### Counting distinct values

```{r counting-distinct}
sql_code <- 
 "select 
  count(age) as n_ages,
  count(distinct age) as n_distinct_ages
  from fat"
```
+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

You can also count the number of distinct values. You might want to do this with a continuous variable like age to see how many plotting positions you would need.

</div>

### Use where to count subset

```{r count-subset}
sql_code <- 
 "select count(case_number) as subset_count
  from fat
  where age >= 65"
```

+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

### Where also computes other statistics on subset

```{r average-subset}
sql_code <- 
 "select 
    round(avg(age)) as avg_senior_age,
    round(avg(bmi)) as avg_senior_bmi
  from fat
  where age >= 65"
```

+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

You can get other summary statistics on a subset. This SQL code produces the average age and average fat percentagle for the 21 senior citizens

</div>

### Switch to titanic data set

```{r shut-down-fat-database-gracefully}
dbDisconnect(conn=db)
```

```{r fire-up-titanic-database}
library(sqldf)
db <- dbConnect(SQLite(), 
  dbname="../data/titanic_db.sqlite")
```

```{r titanic-subgroup}
sql_code <-
 "select PClass, count(Name) as n
  from titanic_table
  where PClass='1st'"
```
+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

This is how you get a count of first class passengers on the Titanic.

</div>

### Use group by to count all subsets

```{r group-by}
sql_code <-
 "select PClass, count(Name) as n
  from titanic_table
  group by PClass"
```
+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

If you wanted a count for every passenger class, use the group by keyword.

</div>

### Multiple categories

```{r group-by-two}
sql_code <- 
 "select Sex, PClass, count(Name) as n
  from titanic_table
  group by Sex, PClass"
```
+ SQL code
```
`r sql_code`
```
+ SQL output
```{r}
dbGetQuery(conn=db, sql_code)
```

<div class="notes">

You can put two or more categorical variables in the GROUP BY statement.

</div>


```{r shut-down-gracefully}
dbDisconnect(conn=db)
```
